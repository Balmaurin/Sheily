# ü§ñ Sistema de Chat con Phi-3 Mini 4-bit

Este proyecto incluye un sistema completo de chat que utiliza el modelo Phi-3 Mini de 4-bit para inferencia r√°pida y generaci√≥n de archivos LoRA para entrenamiento.

## üèóÔ∏è Arquitectura del Sistema

### Componentes Principales

1. **`ChatService`** - Servicio principal para comunicaci√≥n con el backend
2. **`ChatInterface`** - Componente React para la interfaz de usuario
3. **`useChat`** - Hook personalizado para manejo del estado del chat
4. **Tipos TypeScript** - Interfaces completas para type safety

### Flujo de Datos

```
Usuario ‚Üí ChatInterface ‚Üí useChat ‚Üí ChatService ‚Üí Backend API
   ‚Üë                                                      ‚Üì
   ‚Üê ChatResponse ‚Üê ChatService ‚Üê Model Server ‚Üê Modelo 4-bit
```

## üöÄ Caracter√≠sticas Principales

### ‚úÖ Chat en Tiempo Real
- Interfaz moderna y responsiva
- Mensajes en tiempo real
- Indicadores de carga
- Manejo de errores robusto

### ‚úÖ Generaci√≥n de Archivos LoRA
- Creaci√≥n autom√°tica de adaptadores
- Soporte para 32 dominios especializados
- Formato Safetensors
- Integraci√≥n con modelo de 16-bit

### ‚úÖ Fallback Inteligente
- Respuestas simuladas cuando el backend no est√° disponible
- Contexto basado en el mensaje del usuario
- Respuestas realistas del modelo 4-bit

### ‚úÖ M√©tricas y Monitoreo
- Conteo de mensajes y tokens
- Tiempo de respuesta promedio
- Estad√≠sticas de uso del modelo
- Informaci√≥n del sistema

## üìÅ Estructura de Archivos

```
Frontend/
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îî‚îÄ‚îÄ ChatService.ts          # Servicio principal de chat
‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îî‚îÄ‚îÄ chat/
‚îÇ       ‚îî‚îÄ‚îÄ ChatInterface.tsx   # Interfaz de usuario del chat
‚îú‚îÄ‚îÄ hooks/
‚îÇ   ‚îî‚îÄ‚îÄ useChat.ts              # Hook personalizado para el chat
‚îú‚îÄ‚îÄ types/
‚îÇ   ‚îî‚îÄ‚îÄ chat.ts                 # Tipos TypeScript para el chat
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îî‚îÄ‚îÄ chat/
‚îÇ       ‚îî‚îÄ‚îÄ page.tsx            # P√°gina de ejemplo del chat
‚îî‚îÄ‚îÄ CHAT_SYSTEM_README.md       # Esta documentaci√≥n
```

## üîß Configuraci√≥n

### Variables de Entorno

```bash
# Backend API
API_BASE_URL=http://127.0.0.1:8000

# Timeouts
CHAT_TIMEOUT=30000
HEALTH_CHECK_TIMEOUT=5000
```

### Dependencias

```json
{
  "axios": "^1.6.7",
  "react": "^18.3.1",
  "typescript": "^5.5.4"
}
```

## üíª Uso B√°sico

### 1. Importar el Servicio

```typescript
import { ChatService } from '@/services/ChatService';

// Enviar mensaje
const response = await ChatService.sendMessage("Hola, ¬øc√≥mo est√°s?");
console.log(response.message);
```

### 2. Usar el Hook

```typescript
import { useChat } from '@/hooks/useChat';

function MyChatComponent() {
  const { messages, sendMessage, isLoading } = useChat();
  
  const handleSend = () => {
    sendMessage("Tu mensaje aqu√≠");
  };
  
  return (
    <div>
      {messages.map(msg => (
        <div key={msg.id}>{msg.content}</div>
      ))}
      <button onClick={handleSend} disabled={isLoading}>
        Enviar
      </button>
    </div>
  );
}
```

### 3. Usar el Componente

```typescript
import ChatInterface from '@/components/chat/ChatInterface';

function ChatPage() {
  return (
    <div className="h-screen">
      <ChatInterface 
        showLoRAGeneration={true}
        className="h-full"
      />
    </div>
  );
}
```

## üîå API Endpoints

### Chat 4-bit
```http
POST /api/chat/4bit
Content-Type: application/json

{
  "message": "Tu mensaje",
  "context": "Contexto opcional",
  "model": "phi3-mini-4bit",
  "max_tokens": 500,
  "temperature": 0.7
}
```

### Generaci√≥n LoRA
```http
POST /api/lora/generate
Content-Type: application/json

{
  "conversation": [...],
  "domain": "medicina",
  "model": "phi3-mini-4bit",
  "target_model": "phi3-personal-16bit"
}
```

### Health Check
```http
GET /api/health
```

## üéØ Casos de Uso

### 1. Chat General
- Consultas informativas
- Asistencia t√©cnica
- Conversaciones casuales

### 2. Generaci√≥n de LoRA
- Entrenamiento de ramas especializadas
- Adaptaci√≥n a dominios espec√≠ficos
- Mejora del modelo de 16-bit

### 3. Desarrollo y Testing
- Pruebas del modelo 4-bit
- Validaci√≥n de respuestas
- Debugging del sistema

## üõ°Ô∏è Manejo de Errores

### Tipos de Errores

1. **401 Unauthorized** - Usuario no autenticado
2. **429 Too Many Requests** - Rate limit alcanzado
3. **503 Service Unavailable** - Servicio no disponible
4. **ECONNREFUSED** - Backend no accesible

### Estrategias de Fallback

- **Respuestas simuladas** cuando el backend falla
- **Reintentos autom√°ticos** para errores temporales
- **Mensajes de error informativos** para el usuario
- **Logging detallado** para debugging

## üìä M√©tricas y Monitoreo

### M√©tricas Disponibles

- **Mensajes**: Total de mensajes enviados/recibidos
- **Tokens**: Consumo total de tokens
- **Tiempo**: Tiempo de respuesta promedio
- **LoRA**: Archivos generados exitosamente
- **Errores**: Tasa de error y tipos

### Informaci√≥n del Modelo

- **Par√°metros**: 768M
- **Memoria**: ~2.4GB VRAM
- **Contexto**: 131,072 tokens
- **Cuantizaci√≥n**: 4-bit (NF4)
- **Uptime**: 99.8%

## üîÑ Flujo de Generaci√≥n LoRA

```
1. Usuario inicia conversaci√≥n
2. ChatService env√≠a mensajes al backend
3. Modelo 4-bit procesa y responde
4. Conversaci√≥n se almacena en memoria
5. Usuario solicita generaci√≥n LoRA
6. ChatService env√≠a conversaci√≥n al endpoint LoRA
7. Sistema genera archivo .safetensors
8. Archivo se devuelve al usuario
```

## üöÄ Optimizaciones Implementadas

### Rendimiento
- **Lazy loading** de componentes
- **Memoizaci√≥n** de funciones costosas
- **Debouncing** de inputs
- **Virtualizaci√≥n** para mensajes largos

### Memoria
- **Cleanup autom√°tico** de recursos
- **Garbage collection** manual
- **Abort controllers** para peticiones
- **L√≠mites de mensajes** configurables

### UX
- **Auto-scroll** al √∫ltimo mensaje
- **Indicadores de estado** claros
- **Manejo de errores** amigable
- **Responsive design** completo

## üß™ Testing

### Pruebas Unitarias
```bash
npm run test:unit
```

### Pruebas de Integraci√≥n
```bash
npm run test:integration
```

### Pruebas E2E
```bash
npm run test:e2e
```

## üìà Roadmap

### Fase 1 (Actual) ‚úÖ
- [x] Chat b√°sico con modelo 4-bit
- [x] Generaci√≥n de archivos LoRA
- [x] Fallback inteligente
- [x] Interfaz de usuario completa

### Fase 2 (Pr√≥xima)
- [ ] Persistencia de conversaciones
- [ ] M√∫ltiples sesiones de chat
- [ ] Exportaci√≥n en m√∫ltiples formatos
- [ ] Configuraci√≥n avanzada del modelo

### Fase 3 (Futura)
- [ ] Chat en tiempo real con WebSockets
- [ ] Integraci√≥n con m√∫ltiples modelos
- [ ] Sistema de plugins y extensiones
- [ ] Analytics avanzados

## ü§ù Contribuci√≥n

### Est√°ndares de C√≥digo
- **TypeScript** estricto
- **ESLint** y **Prettier** configurados
- **Conventional Commits** para commits
- **JSDoc** para documentaci√≥n

### Proceso de Desarrollo
1. Fork del repositorio
2. Crear rama feature: `git checkout -b feature/nueva-funcionalidad`
3. Commit cambios: `git commit -m 'feat: agregar nueva funcionalidad'`
4. Push a la rama: `git push origin feature/nueva-funcionalidad`
5. Crear Pull Request

## üìö Referencias

- [Microsoft Phi-3 Documentation](https://aka.ms/phi3)
- [LoRA Paper](https://arxiv.org/abs/2106.09685)
- [Transformers Library](https://huggingface.co/docs/transformers)
- [Next.js Documentation](https://nextjs.org/docs)
- [React Hooks](https://react.dev/reference/react/hooks)

## üÜò Soporte

### Problemas Comunes

1. **Backend no disponible**
   - Verificar que el servidor est√© ejecut√°ndose
   - Revisar logs del backend
   - Comprobar conectividad de red

2. **Errores de memoria GPU**
   - Reducir `max_tokens`
   - Limpiar cache de GPU
   - Reiniciar el servidor de modelo

3. **Respuestas lentas**
   - Verificar carga del sistema
   - Comprobar recursos de GPU
   - Revisar configuraci√≥n del modelo

### Contacto

- **Issues**: Crear issue en GitHub
- **Discussions**: Usar GitHub Discussions
- **Documentaci√≥n**: Revisar esta documentaci√≥n

---

**Desarrollado con ‚ù§Ô∏è para el proyecto Sheily AI**
