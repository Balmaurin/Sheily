# Sistema de EvaluaciÃ³n - Shaili AI

## ğŸ“ Estructura del Sistema de EvaluaciÃ³n

```
evaluation/
â”œâ”€â”€ diversity.py                    # ğŸ¯ Evaluador de diversidad lingÃ¼Ã­stica (200+ lÃ­neas)
â”œâ”€â”€ toxicity.py                     # âš ï¸ Evaluador de toxicidad (250+ lÃ­neas)
â”œâ”€â”€ coherence.py                    # ğŸ”— Evaluador de coherencia (280+ lÃ­neas)
â”œâ”€â”€ pipeline.py                     # ğŸ”„ Pipeline de evaluaciÃ³n de calidad (235 lÃ­neas)
â”œâ”€â”€ performance_benchmark.py        # ğŸ“Š Benchmark de rendimiento (250 lÃ­neas)
â”œâ”€â”€ config.py                       # âš™ï¸ ConfiguraciÃ³n del sistema (250 lÃ­neas)
â”œâ”€â”€ setup.py                        # ğŸš€ Script de instalaciÃ³n (288 lÃ­neas)
â”œâ”€â”€ __init__.py                     # ğŸ“¦ Paquete Python funcional (300+ lÃ­neas)
â”œâ”€â”€ test_evaluation_system.py       # ğŸ§ª Sistema de pruebas completo (400+ lÃ­neas)
â””â”€â”€ README.md                       # ğŸ“– Esta documentaciÃ³n
```

## ğŸ“Š EstadÃ­sticas del Sistema

### ğŸ“„ Archivos: 9
### ğŸ’» LÃ­neas de cÃ³digo: 2,000+
### ğŸ Python: 2,000+ lÃ­neas
### ğŸ¯ Evaluadores: 5 clases principales
### âœ… Estado: Completamente funcional

## ğŸ¯ Componentes del Sistema

### 1. **DiversityEvaluator** (`diversity.py`)

#### **FunciÃ³n Principal:**
Evaluar la diversidad lingÃ¼Ã­stica de las respuestas generadas por el modelo de IA.

#### **MÃ©tricas Implementadas:**
- **Riqueza LÃ©xica**:
  - Type-Token Ratio (TTR)
  - Ãndice de Guiraud
  - Ãndice de Herdan
- **Complejidad SintÃ¡ctica**:
  - Longitud promedio de oraciones
  - Variedad de estructuras gramaticales
  - Complejidad de palabras
- **VariaciÃ³n SemÃ¡ntica**:
  - EntropÃ­a de n-gramas (bigramas y trigramas)
  - DispersiÃ³n semÃ¡ntica

#### **Dependencias:**
```python
import numpy as np
import nltk
from nltk.tokenize import word_tokenize, sent_tokenize
from nltk.util import ngrams
from typing import List, Dict, Any
import re
import logging
```

#### **InstalaciÃ³n de Dependencias:**
```bash
pip install numpy nltk
python -m nltk.downloader punkt stopwords
```

#### **Uso:**
```python
from evaluation.diversity import DiversityEvaluator

evaluator = DiversityEvaluator()
diversity_metrics = evaluator.evaluate_diversity(texto)
print(f"Diversidad: {diversity_metrics['diversity_score']}")
```

### 2. **ToxicityEvaluator** (`toxicity.py`)

#### **FunciÃ³n Principal:**
Detectar y evaluar contenido tÃ³xico o inapropiado en las respuestas del modelo.

#### **CategorÃ­as de Toxicidad:**
- **Insultos**: Palabras ofensivas directas
- **DiscriminaciÃ³n**: Lenguaje discriminatorio
- **Sexismo**: Contenido sexista
- **Violencia**: Referencias violentas
- **Odio**: Expresiones de odio

#### **MÃ©tricas Implementadas:**
- **DetecciÃ³n de Lenguaje TÃ³xico**:
  - AnÃ¡lisis lÃ©xico por categorÃ­as
  - PuntuaciÃ³n de severidad
  - DetecciÃ³n de negaciones
- **AnÃ¡lisis Contextual**:
  - Patrones agresivos
  - Uso de mayÃºsculas excesivo
  - AnÃ¡lisis de entidades

#### **Dependencias:**
```python
import re
import numpy as np
from typing import List, Dict, Union, Any
import json
import os
import logging
```

#### **Uso:**
```python
from evaluation.toxicity import ToxicityEvaluator

evaluator = ToxicityEvaluator()
toxicity_result = evaluator.evaluate_toxicity(texto)
print(f"Es tÃ³xico: {toxicity_result['is_toxic']}")
```

### 3. **CoherenceEvaluator** (`coherence.py`)

#### **FunciÃ³n Principal:**
Evaluar la coherencia semÃ¡ntica y lÃ³gica de las respuestas del modelo.

#### **MÃ©tricas Implementadas:**
- **Coherencia SemÃ¡ntica**: Similitud TF-IDF entre consulta y respuesta
- **Relevancia**: Presencia de palabras clave de la consulta
- **Estructura LÃ³gica**: AnÃ¡lisis de conectores lÃ³gicos
- **Consistencia**: VerificaciÃ³n de entidades y coherencia interna

#### **Dependencias:**
```python
import numpy as np
from typing import Dict, Any, List
import re
import logging
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
```

#### **InstalaciÃ³n de Dependencias:**
```bash
pip install scikit-learn
```

#### **Uso:**
```python
from evaluation.coherence import CoherenceEvaluator

evaluator = CoherenceEvaluator()
coherence_score = evaluator.calculate_coherence(query, response)
print(f"Coherencia: {coherence_score}")
```

### 4. **QualityEvaluationPipeline** (`pipeline.py`)

#### **FunciÃ³n Principal:**
Pipeline completo para evaluar la calidad de las respuestas del modelo, combinando mÃºltiples mÃ©tricas.

#### **CaracterÃ­sticas:**
- **EvaluaciÃ³n Integrada**: Combina coherencia, diversidad y toxicidad
- **PuntuaciÃ³n Compuesta**: Peso configurable para cada mÃ©trica
- **Umbrales de Calidad**: ConfiguraciÃ³n de estÃ¡ndares mÃ­nimos
- **Logging Detallado**: Registro de todas las evaluaciones
- **EvaluaciÃ³n de Conversaciones**: AnÃ¡lisis de conversaciones completas

#### **MÃ©tricas Combinadas:**
- **Coherencia** (40%): Relevancia y lÃ³gica
- **Diversidad** (30%): Variedad lingÃ¼Ã­stica
- **Toxicidad** (30%): Ausencia de contenido inapropiado

#### **Uso:**
```python
from evaluation.pipeline import QualityEvaluationPipeline

pipeline = QualityEvaluationPipeline()
evaluation = pipeline.evaluate_response(query, response, domain="ciencia")
print(f"PuntuaciÃ³n: {evaluation['composite_score']}")
```

### 5. **PerformanceBenchmark** (`performance_benchmark.py`)

#### **FunciÃ³n Principal:**
Evaluar el rendimiento y eficiencia de los componentes del sistema de IA.

#### **Componentes Evaluados:**
- **Clustering SemÃ¡ntico**: `AdvancedSemanticClustering`
- **OptimizaciÃ³n de Adapters**: `DomainAdapterOptimizer`
- **ExpansiÃ³n de Dominios**: `DomainExpansionEngine`

#### **MÃ©tricas de Rendimiento:**
- **Tiempo de EjecuciÃ³n**: DuraciÃ³n de operaciones
- **Uso de Memoria**: Consumo de RAM/GPU
- **Escalabilidad**: Rendimiento con diferentes tamaÃ±os de datos
- **Coherencia**: Calidad de resultados

#### **Uso:**
```python
from evaluation.performance_benchmark import PerformanceBenchmark

benchmark = PerformanceBenchmark()
results = benchmark.run_comprehensive_benchmark()
print("Benchmark completado")
```

### 6. **EvaluationConfig** (`config.py`)

#### **FunciÃ³n Principal:**
ConfiguraciÃ³n centralizada del sistema de evaluaciÃ³n.

#### **CaracterÃ­sticas:**
- **Umbrales de Calidad**: ConfiguraciÃ³n de estÃ¡ndares mÃ­nimos
- **Pesos de MÃ©tricas**: ConfiguraciÃ³n de importancia relativa
- **ConfiguraciÃ³n de Logging**: Niveles y formatos de logs
- **ConfiguraciÃ³n de Entorno**: Desarrollo, producciÃ³n, testing

#### **Uso:**
```python
from evaluation.config import EvaluationConfig

# Obtener configuraciÃ³n
thresholds = EvaluationConfig.get_quality_thresholds()
weights = EvaluationConfig.get_quality_weights()

# Crear directorios
EvaluationConfig.create_directories()
```

### 7. **Setup Script** (`setup.py`)

#### **FunciÃ³n Principal:**
Script de instalaciÃ³n automÃ¡tica del sistema de evaluaciÃ³n.

#### **CaracterÃ­sticas:**
- **InstalaciÃ³n de Dependencias**: AutomÃ¡tica con pip
- **Descarga de Recursos**: Modelos NLP y datasets
- **CreaciÃ³n de Directorios**: Estructura de carpetas
- **Pruebas de ImportaciÃ³n**: VerificaciÃ³n de mÃ³dulos
- **Pruebas BÃ¡sicas**: ValidaciÃ³n de funcionalidad

#### **Uso:**
```bash
# InstalaciÃ³n completa
python evaluation/setup.py
```

### 8. **Paquete Python** (`__init__.py`)

#### **FunciÃ³n Principal:**
Transforma la carpeta `evaluation` en un paquete Python funcional.

#### **CaracterÃ­sticas:**
- **API Unificada**: Funciones de conveniencia para evaluaciÃ³n rÃ¡pida
- **Instancias Globales**: GestiÃ³n automÃ¡tica de evaluadores
- **ConfiguraciÃ³n Centralizada**: Acceso fÃ¡cil a configuraciones
- **ValidaciÃ³n AutomÃ¡tica**: VerificaciÃ³n del sistema al importar
- **Reportes**: GeneraciÃ³n automÃ¡tica de reportes de evaluaciÃ³n

#### **Uso:**
```python
import evaluation

# EvaluaciÃ³n rÃ¡pida
diversity_score = evaluation.evaluate_diversity(texto)
toxicity_score = evaluation.evaluate_toxicity(texto)
coherence_score = evaluation.evaluate_coherence(query, response)

# EvaluaciÃ³n completa
quality_result = evaluation.evaluate_quality(query, response, domain="ciencia")

# ValidaciÃ³n del sistema
validation = evaluation.validate_evaluation_system()
```

### 9. **Sistema de Pruebas** (`test_evaluation_system.py`)

#### **FunciÃ³n Principal:**
Sistema completo de pruebas para validar todos los componentes.

#### **CaracterÃ­sticas:**
- **Pruebas Unitarias**: ValidaciÃ³n individual de cada evaluador
- **Pruebas de IntegraciÃ³n**: VerificaciÃ³n del pipeline completo
- **Pruebas de ConfiguraciÃ³n**: ValidaciÃ³n de configuraciones
- **Reportes AutomÃ¡ticos**: GeneraciÃ³n de reportes de pruebas
- **ValidaciÃ³n del Paquete**: Pruebas de importaciÃ³n y API

#### **Uso:**
```bash
# Ejecutar todas las pruebas
python evaluation/test_evaluation_system.py
```

## ğŸ”§ InstalaciÃ³n y ConfiguraciÃ³n

### 1. **InstalaciÃ³n AutomÃ¡tica (Recomendada)**
```bash
# Ejecutar script de instalaciÃ³n
python evaluation/setup.py
```

### 2. **InstalaciÃ³n Manual**
```bash
# Instalar dependencias
pip install numpy nltk scikit-learn matplotlib

# Descargar recursos NLTK
python -m nltk.downloader punkt stopwords

# Crear directorios
mkdir -p logs/evaluation results/evaluation models/evaluation datasets/test
```

### 3. **VerificaciÃ³n de InstalaciÃ³n**
```bash
# Probar todos los evaluadores
python evaluation/diversity.py
python evaluation/toxicity.py
python evaluation/coherence.py
python evaluation/pipeline.py

# Ejecutar pruebas completas
python evaluation/test_evaluation_system.py
```

## ğŸš€ EjecuciÃ³n del Sistema

### **EjecuciÃ³n Individual de Evaluadores**

#### 1. EvaluaciÃ³n de Diversidad
```bash
cd evaluation
python diversity.py
```

#### 2. EvaluaciÃ³n de Toxicidad
```bash
cd evaluation
python toxicity.py
```

#### 3. EvaluaciÃ³n de Coherencia
```bash
cd evaluation
python coherence.py
```

#### 4. Pipeline Completo
```bash
cd evaluation
python pipeline.py
```

#### 5. Benchmark de Rendimiento
```bash
cd evaluation
python performance_benchmark.py
```

### **EjecuciÃ³n del Sistema de Pruebas**
```bash
cd evaluation
python test_evaluation_system.py
```

## ğŸ“Š ConfiguraciÃ³n de MÃ©tricas

### **Umbrales de Calidad (Pipeline)**
```python
pipeline = QualityEvaluationPipeline(
    coherence_weight=0.4,      # Peso de coherencia
    diversity_weight=0.3,      # Peso de diversidad
    toxicity_weight=0.3,       # Peso de toxicidad
    coherence_threshold=0.6,   # Umbral mÃ­nimo de coherencia
    diversity_threshold=0.5,   # Umbral mÃ­nimo de diversidad
    toxicity_threshold=0.3     # Umbral mÃ¡ximo de toxicidad
)
```

### **ConfiguraciÃ³n de Logging**
```python
# Los evaluadores crean automÃ¡ticamente:
# - logs/evaluation/quality_evaluation.log
# - logs/performance/performance_benchmark.log
```

## ğŸ” Estructura de Datos

### **Resultado de EvaluaciÃ³n de Diversidad**
```python
{
    'diversity_score': 0.75,
    'lexical_metrics': {
        'type_token_ratio': 0.65,
        'guiraud_index': 12.3,
        'herdan_index': 0.45
    },
    'syntactic_metrics': {
        'avg_sentence_length': 15.2,
        'max_syntax_depth': 4,
        'pos_diversity': 0.78,
        'word_complexity': 5.8
    },
    'semantic_metrics': {
        'bigram_entropy': 8.5,
        'trigram_entropy': 12.3,
        'semantic_dispersion': 0.67
    }
}
```

### **Resultado de EvaluaciÃ³n de Toxicidad**
```python
{
    'is_toxic': False,
    'toxicity_score': 0.1,
    'base_toxicity': 0.05,
    'context_penalty': 0.03,
    'uppercase_penalty': 0.02,
    'toxic_categories': [],
    'context_analysis': {
        'entidades': ['plantas', 'energÃ­a'],
        'dependencias_agresivas': 0.05,
        'pattern_matches': [],
        'avg_word_length': 6.2,
        'uppercase_ratio': 0.02
    }
}
```

### **Resultado del Pipeline**
```python
{
    'composite_score': 0.82,
    'passes_quality': True,
    'metrics': {
        'coherence': {
            'score': 0.85,
            'passes_threshold': True
        },
        'diversity': {
            'score': 0.75,
            'passes_threshold': True
        },
        'toxicity': {
            'score': 0.90,
            'passes_threshold': True
        }
    },
    'domain': 'ciencia'
}
```

## ğŸ› ï¸ Desarrollo y ExtensiÃ³n

### **Agregar Nuevas MÃ©tricas**

#### 1. Crear Nuevo Evaluador
```python
class CustomEvaluator:
    def __init__(self):
        # InicializaciÃ³n
        pass
    
    def evaluate(self, text: str) -> Dict[str, Any]:
        # LÃ³gica de evaluaciÃ³n
        return {'custom_score': 0.85}
```

#### 2. Integrar en Pipeline
```python
# En pipeline.py
from .custom_evaluator import CustomEvaluator

class QualityEvaluationPipeline:
    def __init__(self):
        self.custom_evaluator = CustomEvaluator()
        # ... resto del cÃ³digo
```

### **Personalizar Umbrales**
```python
# Crear configuraciÃ³n personalizada
config = {
    'coherence_threshold': 0.7,
    'diversity_threshold': 0.6,
    'toxicity_threshold': 0.2,
    'weights': {
        'coherence': 0.5,
        'diversity': 0.3,
        'toxicity': 0.2
    }
}
```

## ğŸ“ˆ Monitoreo y Logs

### **UbicaciÃ³n de Logs**
- **Pipeline**: `logs/evaluation/`
- **Benchmark**: `logs/performance/`
- **Pruebas**: `results/evaluation/`

### **Tipos de Logs**
- **Evaluaciones**: Resultados detallados de cada evaluaciÃ³n
- **Rendimiento**: MÃ©tricas de tiempo y memoria
- **Errores**: Problemas durante la evaluaciÃ³n
- **Pruebas**: Reportes de validaciÃ³n del sistema

### **VisualizaciÃ³n de Resultados**
```python
# El benchmark genera automÃ¡ticamente:
# - performance_visualization.png
# - performance_results.json
# - test_report.json
```

## ğŸ”§ Troubleshooting

### **Problemas Comunes**

#### 1. Error de ImportaciÃ³n de NLTK
```bash
# SoluciÃ³n: Descargar recursos NLTK
python -m nltk.downloader punkt stopwords
```

#### 2. Error de Dependencias Faltantes
```bash
# Instalar dependencias
pip install numpy nltk scikit-learn matplotlib
```

#### 3. Error de ConfiguraciÃ³n
```bash
# Validar configuraciÃ³n
python evaluation/config.py
```

#### 4. Error de Memoria
```bash
# Reducir tamaÃ±o de datos de prueba
test_texts = evaluator.generate_test_data(num_texts=50)
```

## ğŸ“ Notas de ImplementaciÃ³n

### **CaracterÃ­sticas Destacadas**
- âœ… **EvaluaciÃ³n Multi-dimensional**: Combina mÃºltiples mÃ©tricas
- âœ… **ConfiguraciÃ³n Flexible**: Umbrales y pesos ajustables
- âœ… **Logging Detallado**: Registro completo de evaluaciones
- âœ… **VisualizaciÃ³n**: GrÃ¡ficos automÃ¡ticos de rendimiento
- âœ… **Extensibilidad**: FÃ¡cil agregar nuevas mÃ©tricas
- âœ… **Paquete Python**: API unificada y fÃ¡cil de usar
- âœ… **Sistema de Pruebas**: ValidaciÃ³n completa del sistema
- âœ… **Sin Dependencias Externas**: No requiere SpaCy o transformers

### **Mejoras Implementadas**
- ğŸ”§ **EliminaciÃ³n de SpaCy**: Reemplazado con anÃ¡lisis basado en regex y NLTK
- ğŸ”§ **EliminaciÃ³n de Transformers**: Reemplazado con TF-IDF para similitud semÃ¡ntica
- ğŸ”§ **Mejor Manejo de Errores**: ValidaciÃ³n robusta y fallbacks
- ğŸ”§ **API Unificada**: Funciones de conveniencia en el paquete
- ğŸ”§ **Sistema de Pruebas**: ValidaciÃ³n completa de todos los componentes

### **Limitaciones Actuales**
- âš ï¸ **AnÃ¡lisis SintÃ¡ctico**: Limitado sin SpaCy (usando patrones simples)
- âš ï¸ **Similitud SemÃ¡ntica**: Basada en TF-IDF en lugar de embeddings
- âš ï¸ **Recursos de NLP**: Requiere descarga de recursos NLTK

### **Mejoras Futuras**
- ğŸ“‹ **MÃ©tricas Adicionales**: Fluidez, precisiÃ³n, completitud
- ğŸ“‹ **EvaluaciÃ³n AutomÃ¡tica**: IntegraciÃ³n con CI/CD
- ğŸ“‹ **Dashboard Web**: Interfaz para visualizar resultados
- ğŸ“‹ **OptimizaciÃ³n de Rendimiento**: Caching y procesamiento paralelo
- ğŸ“‹ **AnÃ¡lisis SintÃ¡ctico Avanzado**: IntegraciÃ³n con herramientas mÃ¡s sofisticadas

## ğŸ¯ IntegraciÃ³n con Shaili AI

### **Uso en el Sistema Principal**
```python
# En el sistema de IA
import evaluation

# Evaluar respuesta antes de enviar
quality_check = evaluation.evaluate_quality(query, response)

if quality_check['passes_quality']:
    # Enviar respuesta
    send_response(response)
else:
    # Generar respuesta alternativa
    generate_alternative_response()
```

### **Monitoreo Continuo**
```python
# Evaluar calidad de conversaciones completas
conversation_quality = evaluation.evaluate_conversation(conversation)
print(f"Calidad promedio: {conversation_quality['mean_composite_score']}")
```

### **ValidaciÃ³n del Sistema**
```python
# Validar que todo funcione correctamente
validation = evaluation.validate_evaluation_system()
if validation['overall_status']:
    print("âœ… Sistema de evaluaciÃ³n funcionando correctamente")
else:
    print("âŒ Problemas detectados en el sistema de evaluaciÃ³n")
```

## ğŸš€ InstalaciÃ³n RÃ¡pida

### **OpciÃ³n 1: InstalaciÃ³n AutomÃ¡tica (Recomendada)**
```bash
# Clonar o navegar al directorio del proyecto
cd /path/to/shaili-ai

# Ejecutar instalaciÃ³n automÃ¡tica
python evaluation/setup.py
```

### **OpciÃ³n 2: InstalaciÃ³n Manual**
```bash
# 1. Instalar dependencias
pip install numpy nltk scikit-learn matplotlib

# 2. Descargar recursos NLP
python -m nltk.downloader punkt stopwords

# 3. Crear directorios
mkdir -p logs/evaluation results/evaluation models/evaluation datasets/test

# 4. Validar configuraciÃ³n
python evaluation/config.py
```

### **VerificaciÃ³n de InstalaciÃ³n**
```bash
# Probar todos los evaluadores
python evaluation/diversity.py
python evaluation/toxicity.py
python evaluation/coherence.py
python evaluation/pipeline.py

# Ejecutar pruebas completas
python evaluation/test_evaluation_system.py
```

## ğŸ“Š Resultados Esperados

### **Ejemplo de Salida del Pipeline**
```json
{
  "composite_score": 0.82,
  "passes_quality": true,
  "metrics": {
    "coherence": {"score": 0.85, "passes_threshold": true},
    "diversity": {"score": 0.75, "passes_threshold": true},
    "toxicity": {"score": 0.90, "passes_threshold": true}
  }
}
```

### **Ejemplo de Salida de Pruebas**
```json
{
  "test_summary": {
    "total_tests": 7,
    "passed_tests": 7,
    "failed_tests": 0
  },
  "overall_status": true
}
```

---

**Nota**: Este sistema de evaluaciÃ³n es fundamental para garantizar la calidad de las respuestas del modelo de IA. Se recomienda ejecutar evaluaciones regularmente y ajustar los umbrales segÃºn las necesidades especÃ­ficas del proyecto. El sistema estÃ¡ completamente funcional y no requiere dependencias externas complejas.
